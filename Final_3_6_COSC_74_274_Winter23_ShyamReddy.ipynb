{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "      <th>style</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4500</td>\n",
       "      <td>4500</td>\n",
       "      <td>4500</td>\n",
       "      <td>4500</td>\n",
       "      <td>4500</td>\n",
       "      <td>4500</td>\n",
       "      <td>4497</td>\n",
       "      <td>4.500000e+03</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>96</td>\n",
       "      <td>2363</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2317</td>\n",
       "      <td>4455</td>\n",
       "      <td>4312</td>\n",
       "      <td>4069</td>\n",
       "      <td>4418</td>\n",
       "      <td>3460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>1178</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>True</td>\n",
       "      <td>12 26, 2016</td>\n",
       "      <td>D014D493AC2EC7F701D5D5E8827858B4</td>\n",
       "      <td>849AF742279BA95B2DFB8C2D14AAB61D</td>\n",
       "      <td>760C63E8E5E8DC3FAA01878D37BA5678</td>\n",
       "      <td>good</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['https://images-na.ssl-images-amazon.com/imag...</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3581</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>166</td>\n",
       "      <td>22</td>\n",
       "      <td>294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>673</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.409970e+09</td>\n",
       "      <td>7.039046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.135785e+08</td>\n",
       "      <td>16.246092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.090144e+08</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.390565e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.439942e+09</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.479686e+09</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.535069e+09</td>\n",
       "      <td>259.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       verified   reviewTime                        reviewerID  \\\n",
       "count      4500         4500                              4500   \n",
       "unique        2         2317                              4455   \n",
       "top        True  12 26, 2016  D014D493AC2EC7F701D5D5E8827858B4   \n",
       "freq       3581           10                                 4   \n",
       "mean        NaN          NaN                               NaN   \n",
       "std         NaN          NaN                               NaN   \n",
       "min         NaN          NaN                               NaN   \n",
       "25%         NaN          NaN                               NaN   \n",
       "50%         NaN          NaN                               NaN   \n",
       "75%         NaN          NaN                               NaN   \n",
       "max         NaN          NaN                               NaN   \n",
       "\n",
       "                                    asin                      reviewerName  \\\n",
       "count                               4500                              4500   \n",
       "unique                              4312                              4069   \n",
       "top     849AF742279BA95B2DFB8C2D14AAB61D  760C63E8E5E8DC3FAA01878D37BA5678   \n",
       "freq                                   8                               166   \n",
       "mean                                 NaN                               NaN   \n",
       "std                                  NaN                               NaN   \n",
       "min                                  NaN                               NaN   \n",
       "25%                                  NaN                               NaN   \n",
       "50%                                  NaN                               NaN   \n",
       "75%                                  NaN                               NaN   \n",
       "max                                  NaN                               NaN   \n",
       "\n",
       "       reviewText     summary  unixReviewTime        vote  \\\n",
       "count        4500        4497    4.500000e+03  922.000000   \n",
       "unique       4418        3460             NaN         NaN   \n",
       "top          good  Five Stars             NaN         NaN   \n",
       "freq           22         294             NaN         NaN   \n",
       "mean          NaN         NaN    1.409970e+09    7.039046   \n",
       "std           NaN         NaN    1.135785e+08   16.246092   \n",
       "min           NaN         NaN    9.090144e+08    2.000000   \n",
       "25%           NaN         NaN    1.390565e+09    2.000000   \n",
       "50%           NaN         NaN    1.439942e+09    3.000000   \n",
       "75%           NaN         NaN    1.479686e+09    6.000000   \n",
       "max           NaN         NaN    1.535069e+09  259.000000   \n",
       "\n",
       "                                                    image  \\\n",
       "count                                                  96   \n",
       "unique                                                 96   \n",
       "top     ['https://images-na.ssl-images-amazon.com/imag...   \n",
       "freq                                                    1   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                           style    category  \n",
       "count                       2363        4500  \n",
       "unique                      1178           6  \n",
       "top     {'Format:': ' Audio CD'}  automotive  \n",
       "freq                         673         750  \n",
       "mean                         NaN         NaN  \n",
       "std                          NaN         NaN  \n",
       "min                          NaN         NaN  \n",
       "25%                          NaN         NaN  \n",
       "50%                          NaN         NaN  \n",
       "75%                          NaN         NaN  \n",
       "max                          NaN         NaN  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "test_data = pd.read_csv('Test.csv')\n",
    "\n",
    "test_data.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Preprocessing data\n",
    "\n",
    "\n",
    "# edit summary content\n",
    "def edit_text(content):\n",
    "\n",
    "    # step 1 - convert the text to only lower case\n",
    "    content = content.lower()\n",
    "\n",
    "    filtered_words = [word for word in content.split()]\n",
    "    text = \" \".join(filtered_words)\n",
    "\n",
    "    return text\n",
    "\n",
    "# create categories for vote label\n",
    "\n",
    "\n",
    "def assign_vote_label(i):\n",
    "    if i <= 2.0:\n",
    "        return 'low'\n",
    "    if i > 2.0 and i <= 10.0:\n",
    "        return 'medium'\n",
    "    if i > 10.0 and i <= 50.0:\n",
    "        return 'good'\n",
    "    if i > 50.0:\n",
    "        return 'high'\n",
    "\n",
    "\n",
    "# preprocess\n",
    "def preprocess(data):\n",
    "\n",
    "    # filter out only important columns\n",
    "    X_cols = ['reviewText', 'summary', 'verified', 'vote', 'style']\n",
    "\n",
    "    # editing text of \"reviewText\" & \"summary\"\n",
    "    data['reviewText'] = data['reviewText'].astype(str).apply(\n",
    "        edit_text)\n",
    "    data['summary'] = data['summary'].astype(str).apply(edit_text)\n",
    "\n",
    "    # editing vote - assigning NAN values to 0\n",
    "    data['vote'] = data['vote'].fillna(0)\n",
    "    data['vote'] = data['vote'].apply(lambda x: assign_vote_label(x))\n",
    "\n",
    "    data['style'] = data['style'].fillna('')\n",
    "\n",
    "    X = test_data[X_cols]\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = preprocess(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# define the column transformer for all data\n",
    "ct1 = ColumnTransformer(\n",
    "    [\n",
    "        (\"vect_summary\", CountVectorizer(), 'summary'),\n",
    "        (\"vect_reviewText\", CountVectorizer(), 'reviewText'),\n",
    "        (\"vect_style\", CountVectorizer(), 'style'),\n",
    "        (\"encd_verified\", OrdinalEncoder(dtype=int), ['verified']),\n",
    "        (\"encd_votes\", OrdinalEncoder(dtype=int), ['vote']),\n",
    "    ])\n",
    "\n",
    "\n",
    "# define the column transformer for non-text data\n",
    "ct2 = ColumnTransformer(\n",
    "    [\n",
    "        (\"vect_style\", CountVectorizer(), 'style'),\n",
    "        (\"encd_verified\", OrdinalEncoder(dtype=int), ['verified']),\n",
    "        (\"encd_votes\", OrdinalEncoder(dtype=int), ['vote']),\n",
    "    ])\n",
    "\n",
    "# define the column transformer for only text-data\n",
    "ct3 = ColumnTransformer(\n",
    "    [\n",
    "        (\"vect_summary\", CountVectorizer(), 'summary'),\n",
    "        (\"vect_reviewText\", CountVectorizer(), 'reviewText'),\n",
    "    ])\n",
    "\n",
    "# define the column transformer for only style data\n",
    "ct4 = ColumnTransformer(\n",
    "    [\n",
    "        (\"vect_style\", CountVectorizer(), 'style'),\n",
    "    ])\n",
    "\n",
    "# For Results\n",
    "data = []\n",
    "n_clust = []\n",
    "best_sil_score = []\n",
    "best_rand_score = []\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kmeans Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Clusters  silhouette_score  rand_scores\n",
      "0          2          0.669292     0.002898\n",
      "1          3          0.454393     0.011391\n",
      "2          4          0.427389     0.012330\n",
      "3          5          0.346668     0.013058\n",
      "4          6          0.242157     0.013754\n",
      "5          7          0.242090     0.013758\n",
      "6          8          0.207398     0.013897\n",
      "7          9          0.171408     0.014159\n",
      "8         10          0.148355     0.014417\n",
      "9        100         -0.058228     0.029597\n",
      "10       300         -0.069182     0.033779\n",
      "11       500         -0.068950     0.010179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10, 100, 300, 500]\n",
    "sil_scores_1 = []\n",
    "rand_scores_1 = []\n",
    "\n",
    "for n in n_clusters:\n",
    "    # Fit\n",
    "    kmeans = KMeans(n_clusters=n, n_init=10, random_state=101)\n",
    "    transformed_X = ct1.fit_transform(X)\n",
    "    kmeans.fit(transformed_X)\n",
    "\n",
    "    # silhouette score\n",
    "    silhouette_avg = silhouette_score(transformed_X, kmeans.labels_)\n",
    "    sil_scores_1.append(silhouette_avg)\n",
    "\n",
    "    # rand index\n",
    "    ari = adjusted_rand_score(test_data[\"category\"], kmeans.labels_)\n",
    "    rand_scores_1.append(ari)\n",
    "\n",
    "print(pd.DataFrame({\"Clusters\": n_clusters,\n",
    "      \"silhouette_score\": sil_scores_1, \"rand_scores\": rand_scores_1}))\n",
    "\n",
    "data.append(\"All Data\")\n",
    "best_sil_score.append(max(sil_scores_1))\n",
    "n_clust.append(n_clusters[sil_scores_1.index(max(sil_scores_1))])\n",
    "best_rand_score.append(rand_scores_1[sil_scores_1.index(max(sil_scores_1))])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For non-text data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Clusters  silhouette_score  rand_scores\n",
      "0          2          0.363078     0.112200\n",
      "1          3          0.378734     0.158963\n",
      "2          4          0.394763     0.177285\n",
      "3          5          0.406634     0.174259\n",
      "4          6          0.421249     0.163726\n",
      "5          7          0.426161     0.159127\n",
      "6          8          0.414054     0.177877\n",
      "7          9          0.434594     0.182155\n",
      "8         10          0.425720     0.136177\n",
      "9        100          0.621245     0.087932\n",
      "10       300          0.657036     0.086033\n",
      "11       500          0.692069     0.084945\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10, 100, 300, 500]\n",
    "sil_scores_2 = []\n",
    "rand_scores_2 = []\n",
    "\n",
    "for n in n_clusters:\n",
    "    # Fit\n",
    "    kmeans = KMeans(n_clusters=n, n_init=10, random_state=101)\n",
    "    transformed_X = ct2.fit_transform(X)\n",
    "    kmeans.fit(transformed_X)\n",
    "\n",
    "    # silhouette score\n",
    "    silhouette_avg = silhouette_score(transformed_X, kmeans.labels_)\n",
    "    sil_scores_2.append(silhouette_avg)\n",
    "\n",
    "    # rand index\n",
    "    ari = adjusted_rand_score(test_data[\"category\"], kmeans.labels_)\n",
    "    rand_scores_2.append(ari)\n",
    "\n",
    "print(pd.DataFrame({\"Clusters\": n_clusters,\n",
    "      \"silhouette_score\": sil_scores_2, \"rand_scores\": rand_scores_2}))\n",
    "\n",
    "data.append(\"Non-Text Data\")\n",
    "best_sil_score.append(max(sil_scores_2))\n",
    "n_clust.append(n_clusters[sil_scores_2.index(max(sil_scores_2))])\n",
    "best_rand_score.append(rand_scores_2[sil_scores_2.index(max(sil_scores_2))])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For only text data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Clusters  silhouette_score  rand_scores\n",
      "0          2          0.675094     0.002798\n",
      "1          3          0.463293     0.010859\n",
      "2          4          0.437115     0.011946\n",
      "3          5          0.346559     0.012891\n",
      "4          6          0.267419     0.013063\n",
      "5          7          0.250198     0.013527\n",
      "6          8          0.208802     0.013640\n",
      "7          9          0.167885     0.013662\n",
      "8         10          0.159410     0.014268\n",
      "9        100         -0.062177     0.010673\n",
      "10       300         -0.059621     0.009933\n",
      "11       500         -0.059989     0.008167\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10, 100, 300, 500]\n",
    "sil_scores_3 = []\n",
    "rand_scores_3 = []\n",
    "\n",
    "for n in n_clusters:\n",
    "    # Fit\n",
    "    kmeans = KMeans(n_clusters=n, n_init=10, random_state=101)\n",
    "    transformed_X = ct3.fit_transform(X)\n",
    "    kmeans.fit(transformed_X)\n",
    "\n",
    "    # silhouette score\n",
    "    silhouette_avg = silhouette_score(transformed_X, kmeans.labels_)\n",
    "    sil_scores_3.append(silhouette_avg)\n",
    "\n",
    "    # rand index\n",
    "    ari = adjusted_rand_score(test_data[\"category\"], kmeans.labels_)\n",
    "    rand_scores_3.append(ari)\n",
    "\n",
    "print(pd.DataFrame({\"Clusters\": n_clusters,\n",
    "      \"silhouette_score\": sil_scores_3, \"rand_scores\": rand_scores_3}))\n",
    "\n",
    "data.append(\"Only Text Data\")\n",
    "best_sil_score.append(max(sil_scores_3))\n",
    "n_clust.append(n_clusters[sil_scores_3.index(max(sil_scores_3))])\n",
    "best_rand_score.append(rand_scores_2[sil_scores_3.index(max(sil_scores_3))])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For only style data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Clusters  silhouette_score  rand_scores\n",
      "0          2          0.441155     0.112200\n",
      "1          3          0.496103     0.158963\n",
      "2          4          0.536410     0.177285\n",
      "3          5          0.558401     0.174141\n",
      "4          6          0.565777     0.172626\n",
      "5          7          0.579977     0.167456\n",
      "6          8          0.575522     0.167501\n",
      "7          9          0.576248     0.165509\n",
      "8         10          0.590985     0.163837\n",
      "9        100          0.679890     0.161545\n",
      "10       300          0.708331     0.162622\n",
      "11       500          0.733584     0.161114\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10, 100, 300, 500]\n",
    "sil_scores_4 = []\n",
    "rand_scores_4 = []\n",
    "\n",
    "for n in n_clusters:\n",
    "    # Fit\n",
    "    kmeans = KMeans(n_clusters=n, n_init=10, random_state=101)\n",
    "    transformed_X = ct4.fit_transform(X)\n",
    "    kmeans.fit(transformed_X)\n",
    "\n",
    "    # silhouette score\n",
    "    silhouette_avg = silhouette_score(transformed_X, kmeans.labels_)\n",
    "    sil_scores_4.append(silhouette_avg)\n",
    "\n",
    "    # rand index\n",
    "    ari = adjusted_rand_score(test_data[\"category\"], kmeans.labels_)\n",
    "    rand_scores_4.append(ari)\n",
    "\n",
    "print(pd.DataFrame({\"Clusters\": n_clusters,\n",
    "      \"silhouette_score\": sil_scores_4, \"rand_scores\": rand_scores_4}))\n",
    "\n",
    "data.append(\"Only Style Data\")\n",
    "best_sil_score.append(max(sil_scores_4))\n",
    "n_clust.append(n_clusters[sil_scores_4.index(max(sil_scores_4))])\n",
    "best_rand_score.append(rand_scores_4[sil_scores_4.index(max(sil_scores_4))])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data including Text n = 2, provides the best silhouette_score.\n",
    "\n",
    "For data not including Text n >> 6(500), provides the best silhouette_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Used</th>\n",
       "      <th>Number of  clusers</th>\n",
       "      <th>Silhouette score</th>\n",
       "      <th>Rand Index Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All Data</td>\n",
       "      <td>2</td>\n",
       "      <td>0.669292</td>\n",
       "      <td>0.002898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-Text Data</td>\n",
       "      <td>500</td>\n",
       "      <td>0.692069</td>\n",
       "      <td>0.084945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Only Text Data</td>\n",
       "      <td>2</td>\n",
       "      <td>0.675094</td>\n",
       "      <td>0.112200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only Style Data</td>\n",
       "      <td>500</td>\n",
       "      <td>0.733584</td>\n",
       "      <td>0.161114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data Used  Number of  clusers  Silhouette score  Rand Index Score\n",
       "0         All Data                   2          0.669292          0.002898\n",
       "1    Non-Text Data                 500          0.692069          0.084945\n",
       "2   Only Text Data                   2          0.675094          0.112200\n",
       "3  Only Style Data                 500          0.733584          0.161114"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Data Used\": data, \"Number of  clusers\": n_clust,\"Silhouette score\": best_sil_score,\n",
    "              \"Rand Index Score\": best_rand_score}).head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "7b70de28ce7f16dabb42d6daca88e435fe373ac8e95c52d0bdf357ad057a0126"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
